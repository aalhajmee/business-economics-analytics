---
title: "U.S. State Economic Data ETL Process"
author: "Financial Data Analysis and Planning Dashboard"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# U.S. State Economic Data ETL Process

This document describes the Extract, Transform, and Load (ETL) process for collecting, cleaning, and processing U.S. state-level economic indicators from multiple authoritative government sources.

## Data Sources

1. **U.S. Census Bureau - American Community Survey (ACS)**
   - Median Household Income (Table B19013)
   - Poverty Rate (Table B17001)
   - URL: https://www.census.gov/programs-surveys/acs
   - Data Vintage: 2023 (5-year estimates 2019-2023)

2. **Bureau of Labor Statistics (BLS)**
   - Local Area Unemployment Statistics (LAUS)
   - URL: https://www.bls.gov/lau/
   - Data Period: Most recent available month

3. **Missouri Economic Research and Information Center (MERIC)**
   - Cost of Living Data Series
   - URL: https://meric.mo.gov/data/cost-living-data-series
   - Data Vintage: Most recent available quarter

---

## Directory Structure

**Important:** All raw source files must be placed in the `data/state/raw_source/` directory before running this ETL script.

```
data/state/
├── ETL_state_data.Rmd          # This ETL script
├── raw_source/                  # Raw data files (place downloaded files here)
│   ├── ACSDT1Y2023.B19013-*.csv
│   ├── ACSDT1Y2023.B17001-*.csv
│   ├── states_unemployed_numbers_bls_table.xlsx
│   └── 2025 Quarter 3 Cost of Living_Meric_MO_GOV_Table.xlsx
└── State_Data_Demographics.csv  # Output file (generated by this script)
```

The ETL script will automatically search for files in `data/state/raw_source/` first, then fall back to `data/state/` for backward compatibility.

---

## Step 1: Load Required Packages

```{r load-packages}
# Install packages if needed
required_packages <- c("tidyverse", "readr", "dplyr", "readxl")

missing_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages) > 0) {
  install.packages(missing_packages)
}

library(tidyverse)
library(readr)
library(dplyr)
library(readxl)
```

---

## Step 2: Extract Census Data (Median Income and Poverty Rate)

```{r extract-census}
# Load Census B19013 (Median Household Income)
cat("Loading Census B19013 (Median Income) data...\n")

# Find the income file (handle different working directories)
income_file <- NULL

# Try relative paths first
possible_paths <- c(
  "data/state/raw_source/ACSDT1Y2023.B19013-2025-11-19T004509.csv",
  "raw_source/ACSDT1Y2023.B19013-2025-11-19T004509.csv",
  "ACSDT1Y2023.B19013-2025-11-19T004509.csv"
)

for(path in possible_paths) {
  if(file.exists(path)) {
    income_file <- path
    break
  }
}

# If still not found, search for any B19013 file in data/state/raw_source
if(is.null(income_file)) {
  if(dir.exists("data/state/raw_source")) {
    csv_files <- list.files("data/state/raw_source", pattern = "B19013.*\\.csv$", full.names = TRUE)
    if(length(csv_files) > 0) {
      income_file <- csv_files[1]
      cat("Found income file:", income_file, "\n")
    }
  }
  # Also check data/state directory (backward compatibility)
  if(is.null(income_file) && dir.exists("data/state")) {
    csv_files <- list.files("data/state", pattern = "B19013.*\\.csv$", full.names = TRUE)
    if(length(csv_files) > 0) {
      income_file <- csv_files[1]
      cat("Found income file:", income_file, "\n")
    }
  }
}

# Try absolute path from project root
if(is.null(income_file)) {
  project_root <- getwd()
  abs_path <- file.path(project_root, "data/state/raw_source/ACSDT1Y2023.B19013-2025-11-19T004509.csv")
  if(file.exists(abs_path)) {
    income_file <- abs_path
  }
}

if(is.null(income_file) || !file.exists(income_file)) {
  stop("Census income file not found. Please ensure ACSDT1Y2023.B19013-*.csv is in data/state/raw_source/ directory")
}

income_raw <- read_csv(income_file, show_col_types = FALSE, locale = locale(encoding = "UTF-8"))

# Extract the row with median income (first data row after header)
income_row <- income_raw[1, ]

# Select only Estimate columns (exclude Margin of Error columns)
estimate_cols <- names(income_row)[str_detect(names(income_row), "!!Estimate")]

# Transform from wide to long format
income_long <- income_row %>%
  select(all_of(c("Label (Grouping)", estimate_cols))) %>%
  select(-`Label (Grouping)`) %>%
  pivot_longer(everything(), names_to = "state_col", values_to = "value") %>%
  mutate(
    State = str_replace(state_col, "!!Estimate", ""),
    Median_Income = as.numeric(str_replace_all(value, ",", ""))
  ) %>%
  select(State, Median_Income) %>%
  filter(!is.na(Median_Income))

cat("Extracted median income for", nrow(income_long), "states\n")

# Load Census B17001 (Poverty Status)
cat("Loading Census B17001 (Poverty) data...\n")

# Find the poverty file (handle different working directories)
poverty_file <- NULL

# Try relative paths first
possible_paths <- c(
  "data/state/raw_source/ACSDT1Y2023.B17001-2025-11-19T004543.csv",
  "raw_source/ACSDT1Y2023.B17001-2025-11-19T004543.csv",
  "ACSDT1Y2023.B17001-2025-11-19T004543.csv"
)

for(path in possible_paths) {
  if(file.exists(path)) {
    poverty_file <- path
    break
  }
}

# If still not found, search for any B17001 file in data/state/raw_source
if(is.null(poverty_file)) {
  if(dir.exists("data/state/raw_source")) {
    csv_files <- list.files("data/state/raw_source", pattern = "B17001.*\\.csv$", full.names = TRUE)
    if(length(csv_files) > 0) {
      poverty_file <- csv_files[1]
      cat("Found poverty file:", poverty_file, "\n")
    }
  }
  # Also check data/state directory (backward compatibility)
  if(is.null(poverty_file) && dir.exists("data/state")) {
    csv_files <- list.files("data/state", pattern = "B17001.*\\.csv$", full.names = TRUE)
    if(length(csv_files) > 0) {
      poverty_file <- csv_files[1]
      cat("Found poverty file:", poverty_file, "\n")
    }
  }
}

# Try absolute path from project root
if(is.null(poverty_file)) {
  project_root <- getwd()
  abs_path <- file.path(project_root, "data/state/raw_source/ACSDT1Y2023.B17001-2025-11-19T004543.csv")
  if(file.exists(abs_path)) {
    poverty_file <- abs_path
  }
}

if(is.null(poverty_file) || !file.exists(poverty_file)) {
  stop("Census poverty file not found. Please ensure ACSDT1Y2023.B17001-*.csv is in data/state/raw_source/ directory")
}

poverty_raw <- read_csv(poverty_file, show_col_types = FALSE, locale = locale(encoding = "UTF-8"))

# Find rows: "Total:" (B17001_001) and "Income in the past 12 months below poverty level:" (B17001_002)
# Note: The labels may have leading whitespace, so we trim them
poverty_raw$`Label (Grouping)` <- str_trim(poverty_raw$`Label (Grouping)`)

total_row_idx <- which(poverty_raw$`Label (Grouping)` == "Total:")
below_poverty_row_idx <- which(str_detect(poverty_raw$`Label (Grouping)`, "Income in the past 12 months below poverty level:"))

if(length(total_row_idx) == 0) {
  cat("Available row labels (first 10):\n")
  print(head(poverty_raw$`Label (Grouping)`, 10))
  stop("Could not find 'Total:' row in poverty data")
}

if(length(below_poverty_row_idx) == 0) {
  cat("Searching for poverty row... Available row labels containing 'poverty':\n")
  poverty_rows <- poverty_raw$`Label (Grouping)`[str_detect(poverty_raw$`Label (Grouping)`, "poverty|Poverty", ignore.case = TRUE)]
  print(head(poverty_rows, 5))
  stop("Could not find 'Income in the past 12 months below poverty level:' row in poverty data")
}

# Extract total and below poverty estimates
total_row <- poverty_raw[total_row_idx, ]
below_poverty_row <- poverty_raw[below_poverty_row_idx[1], ]

# Select only Estimate columns (exclude Margin of Error columns)
estimate_cols <- names(total_row)[str_detect(names(total_row), "!!Estimate")]

# Transform both to long format
total_long <- total_row %>%
  select(all_of(c("Label (Grouping)", estimate_cols))) %>%
  select(-`Label (Grouping)`) %>%
  pivot_longer(everything(), names_to = "state_col", values_to = "value") %>%
  mutate(
    State = str_replace(state_col, "!!Estimate", ""),
    Total = as.numeric(str_replace_all(value, ",", ""))
  ) %>%
  select(State, Total)

below_poverty_long <- below_poverty_row %>%
  select(all_of(c("Label (Grouping)", estimate_cols))) %>%
  select(-`Label (Grouping)`) %>%
  pivot_longer(everything(), names_to = "state_col", values_to = "value") %>%
  mutate(
    State = str_replace(state_col, "!!Estimate", ""),
    Below_Poverty = as.numeric(str_replace_all(value, ",", ""))
  ) %>%
  select(State, Below_Poverty)

# Calculate poverty rate
poverty_summary <- total_long %>%
  left_join(below_poverty_long, by = "State") %>%
  mutate(
    Poverty_Rate = (Below_Poverty / Total) * 100
  ) %>%
  select(State, Poverty_Rate) %>%
  filter(!is.na(Poverty_Rate))

cat("Calculated poverty rate for", nrow(poverty_summary), "states\n")

# Combine income and poverty
census_data <- income_long %>%
  left_join(poverty_summary, by = "State")

cat("Combined Census data for", nrow(census_data), "states\n")
```

---

## Step 3: Extract BLS Unemployment Data

```{r extract-bls}
# Load BLS unemployment data from Excel
cat("Loading BLS unemployment data...\n")

# Find the BLS file (handle different working directories)
bls_file <- NULL

# Try relative paths first
possible_paths <- c(
  "data/state/raw_source/states_unemployed_numbers_bls_table.xlsx",
  "raw_source/states_unemployed_numbers_bls_table.xlsx",
  "states_unemployed_numbers_bls_table.xlsx"
)

for(path in possible_paths) {
  if(file.exists(path)) {
    bls_file <- path
    break
  }
}

# If still not found, search for any BLS Excel file in data/state/raw_source
if(is.null(bls_file)) {
  if(dir.exists("data/state/raw_source")) {
    xlsx_files <- list.files("data/state/raw_source", pattern = ".*bls.*\\.xlsx$|.*unemployed.*\\.xlsx$", full.names = TRUE, ignore.case = TRUE)
    if(length(xlsx_files) > 0) {
      bls_file <- xlsx_files[1]
      cat("Found BLS file:", bls_file, "\n")
    }
  }
  # Also check data/state directory (backward compatibility)
  if(is.null(bls_file) && dir.exists("data/state")) {
    xlsx_files <- list.files("data/state", pattern = ".*bls.*\\.xlsx$|.*unemployed.*\\.xlsx$", full.names = TRUE, ignore.case = TRUE)
    if(length(xlsx_files) > 0) {
      bls_file <- xlsx_files[1]
      cat("Found BLS file:", bls_file, "\n")
    }
  }
}

# Try absolute path from project root
if(is.null(bls_file)) {
  project_root <- getwd()
  abs_path <- file.path(project_root, "data/state/raw_source/states_unemployed_numbers_bls_table.xlsx")
  if(file.exists(abs_path)) {
    bls_file <- abs_path
  }
}

if(is.null(bls_file) || !file.exists(bls_file)) {
  stop("BLS file not found. Please ensure states_unemployed_numbers_bls_table.xlsx is in data/state/raw_source/ directory")
}

# Read the cleaned table sheet with headers first to find column positions
bls_headers <- read_excel(bls_file, sheet = "Table_cleaned", n_max = 3)

# Find percent columns (they should be around columns 10-13)
percent_col_idx <- which(str_detect(names(bls_headers), "Percent of labor force"))

if(length(percent_col_idx) == 0) {
  cat("Available columns:", paste(names(bls_headers), collapse = ", "), "\n")
  stop("Could not find 'Percent of labor force' columns in BLS data")
}

# Use the most recent month (last percent column, typically column 13 for Aug 2024)
rate_col_idx <- max(percent_col_idx)
rate_col_name <- names(bls_headers)[rate_col_idx]

cat("Using unemployment rate column:", rate_col_name, " (column", rate_col_idx, ")\n")

# Now read the data skipping first 3 header rows
bls_data <- read_excel(bls_file, sheet = "Table_cleaned", skip = 3, col_names = FALSE)

# Extract State (column 1) and Unemployment Rate (the percent column we found)
# When reading with col_names = FALSE, columns are named ...1, ...2, etc.
# Use base R indexing to extract columns, then convert to tibble
unemployment_df <- data.frame(
  State = as.character(bls_data[[1]]),
  Unemployment_Rate = bls_data[[rate_col_idx]],
  stringsAsFactors = FALSE
) %>%
  mutate(
    # Convert to numeric, handling any character values or "######" placeholders
    Unemployment_Rate = ifelse(Unemployment_Rate == "######" | is.na(Unemployment_Rate), 
                              NA_character_, as.character(Unemployment_Rate)),
    Unemployment_Rate = as.numeric(gsub("[^0-9.]", "", Unemployment_Rate))
  ) %>%
  filter(!is.na(State), State != "State", !is.na(Unemployment_Rate)) %>%
  # Values should already be percentages (e.g., 3.1 = 3.1%), ensure they're in correct range
  mutate(
    # If value is > 100, it might be in wrong format (e.g., 310 instead of 3.1)
    Unemployment_Rate = ifelse(Unemployment_Rate > 100, Unemployment_Rate / 100, Unemployment_Rate),
    # If value is between 10-100, it might need division by 10 (e.g., 31 instead of 3.1)
    Unemployment_Rate = ifelse(Unemployment_Rate >= 10 & Unemployment_Rate < 100, Unemployment_Rate / 10, Unemployment_Rate)
  )

cat("Loaded BLS unemployment data for", nrow(unemployment_df), "states\n")
```

---

## Step 4: Extract MERIC Cost of Living Data

```{r extract-meric}
# Load MERIC cost of living data from Excel
cat("Loading MERIC cost of living data...\n")

# Find the MERIC file (handle different working directories)
meric_file <- NULL

# Try relative paths first
possible_paths <- c(
  "data/state/raw_source/2025 Quarter 3 Cost of Living_Meric_MO_GOV_Table.xlsx",
  "raw_source/2025 Quarter 3 Cost of Living_Meric_MO_GOV_Table.xlsx",
  "2025 Quarter 3 Cost of Living_Meric_MO_GOV_Table.xlsx"
)

for(path in possible_paths) {
  if(file.exists(path)) {
    meric_file <- path
    break
  }
}

# If still not found, search for any MERIC Excel file in data/state/raw_source
if(is.null(meric_file)) {
  if(dir.exists("data/state/raw_source")) {
    xlsx_files <- list.files("data/state/raw_source", pattern = ".*meric.*\\.xlsx$|.*cost.*living.*\\.xlsx$", full.names = TRUE, ignore.case = TRUE)
    if(length(xlsx_files) > 0) {
      meric_file <- xlsx_files[1]
      cat("Found MERIC file:", meric_file, "\n")
    }
  }
  # Also check data/state directory (backward compatibility)
  if(is.null(meric_file) && dir.exists("data/state")) {
    xlsx_files <- list.files("data/state", pattern = ".*meric.*\\.xlsx$|.*cost.*living.*\\.xlsx$", full.names = TRUE, ignore.case = TRUE)
    if(length(xlsx_files) > 0) {
      meric_file <- xlsx_files[1]
      cat("Found MERIC file:", meric_file, "\n")
    }
  }
}

# Try absolute path from project root
if(is.null(meric_file)) {
  project_root <- getwd()
  abs_path <- file.path(project_root, "data/state/raw_source/2025 Quarter 3 Cost of Living_Meric_MO_GOV_Table.xlsx")
  if(file.exists(abs_path)) {
    meric_file <- abs_path
  }
}

if(is.null(meric_file) || !file.exists(meric_file)) {
  stop("MERIC file not found. Please ensure 2025 Quarter 3 Cost of Living_Meric_MO_GOV_Table.xlsx is in data/state/raw_source/ directory")
}

# Read the first sheet
meric_data <- read_excel(meric_file, sheet = "Sheet1")

# Identify state and cost of living index columns
# MERIC file has: Rank, State, Index, Grocery, Housing, etc.
state_col <- NULL
coli_col <- NULL

# Show available columns for debugging
cat("Available MERIC columns:", paste(names(meric_data), collapse = ", "), "\n")

for(col in names(meric_data)) {
  col_lower <- tolower(col)
  if(is.null(state_col) && (col_lower == "state" || 
                             col_lower == "state name" || 
                             col_lower == "area")) {
    state_col <- col
  }
  # Look for "Index" column (the cost of living index)
  if(is.null(coli_col) && (col_lower == "index" ||
                            col_lower == "cost of living index" ||
                            col_lower == "coli")) {
    coli_col <- col
  }
}

# If still not found, try more flexible patterns
if(is.null(state_col)) {
  state_candidates <- names(meric_data)[str_detect(tolower(names(meric_data)), "^state$")]
  if(length(state_candidates) > 0) {
    state_col <- state_candidates[1]
    cat("Found State column:", state_col, "\n")
  }
}

if(is.null(coli_col)) {
  # Look for "Index" column (case insensitive)
  index_candidates <- names(meric_data)[tolower(names(meric_data)) == "index"]
  if(length(index_candidates) > 0) {
    coli_col <- index_candidates[1]
    cat("Found Index column:", coli_col, "\n")
  }
}

if(is.null(state_col) || is.null(coli_col)) {
  cat("\nCould not identify columns. Available columns:\n")
  print(names(meric_data))
  stop("Could not identify State or Cost of Living Index columns in MERIC data")
}

# Extract and clean
meric_df <- meric_data %>%
  select(State = !!sym(state_col), Cost_of_Living_Index = !!sym(coli_col)) %>%
  mutate(
    State = str_trim(as.character(State)),  # Remove leading/trailing whitespace
    Cost_of_Living_Index = as.numeric(Cost_of_Living_Index)
  ) %>%
  filter(!is.na(State), !is.na(Cost_of_Living_Index))

cat("Loaded MERIC cost of living data for", nrow(meric_df), "states\n")
```

---

## Step 5: Transform and Merge Data

```{r transform-merge}
# Create state code mapping
state_codes <- data.frame(
  State = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado",
            "Connecticut", "Delaware", "District of Columbia", "Florida", "Georgia",
            "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky",
            "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota",
            "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire",
            "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota",
            "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina",
            "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia",
            "Washington", "West Virginia", "Wisconsin", "Wyoming", "Puerto Rico"),
  State_Code = c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "DC", "FL", "GA",
                 "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA",
                 "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY",
                 "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", "SD", "TN", "TX",
                 "UT", "VT", "VA", "WA", "WV", "WI", "WY", "PR"),
  stringsAsFactors = FALSE
)

# Merge all data sources
cat("Merging data from all sources...\n")

state_data <- census_data %>%
  left_join(unemployment_df, by = "State") %>%
  left_join(meric_df, by = "State") %>%
  left_join(state_codes, by = "State") %>%
  select(State, State_Code, Median_Income, Unemployment_Rate, Poverty_Rate, Cost_of_Living_Index) %>%
  arrange(State)

cat("Merged data for", nrow(state_data), "states/territories\n")
```

---

## Step 6: Data Cleaning and Validation

```{r clean-validate}
# Remove territories (keep only 50 states + DC if needed)
state_data_clean <- state_data %>%
  filter(!State %in% c("Puerto Rico")) %>%
  # Round numeric values appropriately
  mutate(
    Median_Income = round(Median_Income, 0),
    Unemployment_Rate = round(Unemployment_Rate, 1),
    Poverty_Rate = round(Poverty_Rate, 1),
    Cost_of_Living_Index = round(Cost_of_Living_Index, 1)
  )

# Check for missing values
cat("\nData Completeness Check:\n")
cat("States with missing Median Income:", sum(is.na(state_data_clean$Median_Income)), "\n")
cat("States with missing Unemployment Rate:", sum(is.na(state_data_clean$Unemployment_Rate)), "\n")
cat("States with missing Poverty Rate:", sum(is.na(state_data_clean$Poverty_Rate)), "\n")
cat("States with missing Cost of Living Index:", sum(is.na(state_data_clean$Cost_of_Living_Index)), "\n")

# Summary statistics
cat("\nSummary Statistics:\n")
summary(state_data_clean %>% select(-State, -State_Code))
```

---

## Step 7: Load - Save Cleaned Data

```{r save-data}
# Ensure output directory exists
# Use absolute path from project root to avoid nesting issues
# Find project root by looking for ui.R or server.R files
find_project_root <- function() {
  current_dir <- getwd()
  max_depth <- 5
  depth <- 0
  
  while(depth < max_depth) {
    # Check if we're in project root (has ui.R or server.R)
    if(file.exists(file.path(current_dir, "ui.R")) || 
       file.exists(file.path(current_dir, "server.R"))) {
      return(normalizePath(current_dir))
    }
    # Go up one level
    parent_dir <- dirname(current_dir)
    if(parent_dir == current_dir) {
      # We've reached the filesystem root
      break
    }
    current_dir <- parent_dir
    depth <- depth + 1
  }
  
  # Fallback: if we're in data/state, go up two levels
  if(basename(getwd()) == "state" && 
     basename(dirname(getwd())) == "data") {
    return(normalizePath("../.."))
  }
  
  # Last resort: use current working directory
  return(normalizePath(getwd()))
}

project_root <- find_project_root()
cat("Project root detected:", project_root, "\n")

output_dir <- file.path(project_root, "data", "state")
if(!dir.exists(file.path(project_root, "data"))) {
  dir.create(file.path(project_root, "data"), recursive = TRUE)
}
if(!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
  cat("Created directory:", output_dir, "\n")
}

# Check data completeness before saving
missing_unemployment <- sum(is.na(state_data_clean$Unemployment_Rate))
missing_coli <- sum(is.na(state_data_clean$Cost_of_Living_Index))
missing_income <- sum(is.na(state_data_clean$Median_Income))
missing_poverty <- sum(is.na(state_data_clean$Poverty_Rate))

if(missing_unemployment > 0 || missing_coli > 0 || missing_income > 0 || missing_poverty > 0) {
  cat("\nWARNING: Incomplete data detected!\n")
  if(missing_income > 0) cat("  - Missing Median Income:", missing_income, "states\n")
  if(missing_poverty > 0) cat("  - Missing Poverty Rate:", missing_poverty, "states\n")
  if(missing_unemployment > 0) cat("  - Missing Unemployment Rate:", missing_unemployment, "states\n")
  if(missing_coli > 0) cat("  - Missing Cost of Living Index:", missing_coli, "states\n")
  cat("\nProceeding to save data with missing values...\n")
}

# Save to CSV - use absolute path
output_file <- file.path(output_dir, "State_Data_Demographics.csv")
cat("Saving to:", output_file, "\n")

write_csv(state_data_clean, output_file)

cat("\nData saved to:", output_file, "\n")
cat("Total rows:", nrow(state_data_clean), "\n")
cat("Total columns:", ncol(state_data_clean), "\n")

# Display first few rows
cat("\nFirst 10 rows of cleaned data:\n")
print(head(state_data_clean, 10))
```

---

## Step 8: Data Quality Report

```{r quality-report}
cat("\n=== DATA QUALITY REPORT ===\n\n")

cat("1. Coverage:\n")
cat("   - Total states/territories:", nrow(state_data_clean), "\n")
cat("   - 50 U.S. states:", sum(!state_data_clean$State %in% c("District of Columbia", "Puerto Rico")), "\n\n")

cat("2. Data Completeness:\n")
completeness <- state_data_clean %>%
  summarise(
    Median_Income = sum(!is.na(Median_Income)) / n() * 100,
    Unemployment_Rate = sum(!is.na(Unemployment_Rate)) / n() * 100,
    Poverty_Rate = sum(!is.na(Poverty_Rate)) / n() * 100,
    Cost_of_Living_Index = sum(!is.na(Cost_of_Living_Index)) / n() * 100
  )
print(completeness)
cat("\n")

cat("3. Data Ranges:\n")
if(sum(!is.na(state_data_clean$Median_Income)) > 0) {
  cat("   Median Income: $", min(state_data_clean$Median_Income, na.rm = TRUE), 
      " to $", max(state_data_clean$Median_Income, na.rm = TRUE), "\n")
}
if(sum(!is.na(state_data_clean$Unemployment_Rate)) > 0) {
  cat("   Unemployment Rate: ", min(state_data_clean$Unemployment_Rate, na.rm = TRUE), 
      "% to ", max(state_data_clean$Unemployment_Rate, na.rm = TRUE), "%\n")
}
if(sum(!is.na(state_data_clean$Poverty_Rate)) > 0) {
  cat("   Poverty Rate: ", min(state_data_clean$Poverty_Rate, na.rm = TRUE), 
      "% to ", max(state_data_clean$Poverty_Rate, na.rm = TRUE), "%\n")
}
if(sum(!is.na(state_data_clean$Cost_of_Living_Index)) > 0) {
  cat("   Cost of Living Index: ", min(state_data_clean$Cost_of_Living_Index, na.rm = TRUE), 
      " to ", max(state_data_clean$Cost_of_Living_Index, na.rm = TRUE), "\n")
}
cat("\n")

cat("4. Data Sources:\n")
cat("   - Median Income: U.S. Census Bureau ACS 2023 5-Year Estimates (Table B19013)\n")
cat("   - Poverty Rate: U.S. Census Bureau ACS 2023 5-Year Estimates (Table B17001)\n")
cat("   - Unemployment Rate: BLS Local Area Unemployment Statistics (LAUS)\n")
cat("   - Cost of Living Index: MERIC Cost of Living Data Series\n")
```

---

## Citations and Data Attribution

**U.S. Census Bureau:**
```
U.S. Census Bureau. (2023). American Community Survey 5-Year Estimates.
Retrieved from https://www.census.gov/programs-surveys/acs
License: Public Domain (U.S. Government Work)
```

**Bureau of Labor Statistics:**
```
U.S. Bureau of Labor Statistics. Local Area Unemployment Statistics.
Retrieved from https://www.bls.gov/lau/
License: Public Domain (U.S. Government Work)
```

**MERIC:**
```
Missouri Economic Research and Information Center. Cost of Living Data Series.
Retrieved from https://meric.mo.gov/data/cost-living-data-series
License: Public Domain (State Government Work)
```

---

## Data Licensing and Distribution

### U.S. Census Bureau Data (ACS)

**License:** Public Domain (U.S. Government Work)

- **Status:** Freely available and redistributable
- **Restrictions:** 
  - Cannot be used to identify individuals or establishments
  - Intended for statistical analysis and research purposes
- **Attribution:** Recommended but not required
- **Source:** [Census Bureau Terms of Service](https://www.census.gov/data/developers/terms-of-service.html)

**Can you redistribute?** ✅ **YES** - Public domain data, freely redistributable

### Bureau of Labor Statistics (BLS) Data

**License:** Public Domain (U.S. Government Work)

- **Status:** Freely available and redistributable
- **Restrictions:** None for public use
- **Attribution:** Recommended but not required
- **Source:** BLS data is produced by a U.S. federal agency

**Can you redistribute?** ✅ **YES** - Public domain data, freely redistributable

### MERIC (Missouri Economic Research and Information Center) Data

**License:** Public Domain (State Government Work)

- **Status:** Publicly available data from Missouri state agency
- **Restrictions:** Generally none for public use, but check website for updates
- **Attribution:** Recommended
- **Source:** [MERIC Website](https://meric.mo.gov/data/cost-living-data-series)

**Can you redistribute?** ✅ **YES** - State government data, typically public domain and redistributable

### Summary

**All three data sources are public domain government data and can be freely redistributed.** However, you should:

1. **Attribute sources** in your documentation (as done in this ETL file)
2. **Not use Census data to identify individuals** (statistical use only)
3. **Include citations** when publishing or sharing the processed dataset

The final merged dataset (`State_Data_Demographics.csv`) can be included in your project repository and distributed freely.

---

**ETL Process Completed Successfully**

The cleaned state economic data has been saved to `data/state/State_Data_Demographics.csv` and is ready for use in the Financial Data Analysis and Planning Dashboard.
